{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGa2pE96kr6k7yuq/anU4c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GinaQurrotaAeny29/2306029_ForwardChaining-BackwardChaining_4/blob/main/Tugas4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLVPsVJbZP12",
        "outputId": "db8a1327-30e1-4fa3-b3d4-2cdccce35638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting experta\n",
            "  Downloading experta-1.9.4-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting frozendict==1.2 (from experta)\n",
            "  Downloading frozendict-1.2.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.6.7 (from experta)\n",
            "  Downloading schema-0.6.7-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Downloading experta-1.9.4-py3-none-any.whl (35 kB)\n",
            "Downloading schema-0.6.7-py2.py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-py3-none-any.whl size=3149 sha256=ea45f406f23ec38bb97761b1151abe4b9cb30485f11456593aa5a5109a5ade51\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ac/f8/cb8120244e710bdb479c86198b03c7b08c3c2d3d2bf448fd6e\n",
            "Successfully built frozendict\n",
            "Installing collected packages: schema, frozendict, experta\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 2.4.6\n",
            "    Uninstalling frozendict-2.4.6:\n",
            "      Successfully uninstalled frozendict-2.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.55 requires frozendict>=2.3.4, but you have frozendict 1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed experta-1.9.4 frozendict-1.2 schema-0.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install experta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade frozendict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC3fIP-PZtHh",
        "outputId": "baf57665-ed72-41b6-f974-0fab09bcf816"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
            "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
            "Installing collected packages: frozendict\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 1.2\n",
            "    Uninstalling frozendict-1.2:\n",
            "      Successfully uninstalled frozendict-1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "experta 1.9.4 requires frozendict==1.2, but you have frozendict 2.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed frozendict-2.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class Diagnosis(KnowledgeEngine):\n",
        "\n",
        "    @Rule(Fact(cough=True) & Fact(fever=True) & Fact(fatigue=True))\n",
        "    def flu(self):\n",
        "        print(\"Diagnosis: You may have the flu.\")\n",
        "\n",
        "    @Rule(Fact(cough=True) & Fact(fever=True) & Fact(breathing_difficulity=False))\n",
        "    def pneumonia(self):\n",
        "        print(\"Diagnosis: You may have Pneumonia.\")\n",
        "\n",
        "    @Rule(Fact(sneezing=True) & Fact(runny_nose=True) & Fact(cough=True))\n",
        "    def cold(self):\n",
        "        print(\"Diagnosis: You may have Common Cold.\")\n",
        "\n",
        "    @Rule(Fact(sore_throat=True) & Fact(fever=True))\n",
        "    def throat_infection(self):\n",
        "        print(\"Diagnosis: You may have a Throat Infection.\")\n",
        "\n",
        "    @Rule(Fact(cough=False) & Fact(fever=False) & Fact(fatigue=False))\n",
        "    def healthy(self):\n",
        "        print(\"Diagnosis: You are healthy.\")\n",
        "\n",
        "    # --- Tambahan Penyakit ---\n",
        "\n",
        "    @Rule(Fact(cough=True) & Fact(fever=True) & Fact(breathing_difficulity=True) & Fact(fatigue=True) & Fact(sore_throat=True))\n",
        "    def covid19(self):\n",
        "        print(\"Diagnosis: You may have COVID-19.\")\n",
        "\n",
        "    @Rule(Fact(breathing_difficulity=True) & Fact(cough=True) & Fact(fatigue=False))\n",
        "    def asthma(self):\n",
        "        print(\"Diagnosis: You may have Asthma.\")\n",
        "\n",
        "    @Rule(Fact(sneezing=True) & Fact(runny_nose=True) & Fact(cough=False) & Fact(fever=False))\n",
        "    def allergy(self):\n",
        "        print(\"Diagnosis: You may have Allergies.\")\n",
        "\n",
        "    @Rule(Fact(sore_throat=True) & Fact(fever=True) & Fact(cough=True))\n",
        "    def tonsilitis(self):\n",
        "        print(\"Diagnosis: You may have Tonsillitis.\")\n",
        "\n",
        "def get_input():\n",
        "    \"\"\"Helper function to get user input.\"\"\"\n",
        "    def ask_question(question):\n",
        "        return input(question + \" (yes/no): \").strip().lower() == \"yes\"\n",
        "\n",
        "    return {\n",
        "        \"cough\": ask_question(\"Do you have a cough?\"),\n",
        "        \"fever\": ask_question(\"Do you have a fever?\"),\n",
        "        \"fatigue\": ask_question(\"Do you feel fatigue?\"),\n",
        "        \"breathing_difficulity\": ask_question(\"Do you have breathing difficulty?\"),\n",
        "        \"sneezing\": ask_question(\"Are you sneezing?\"),\n",
        "        \"runny_nose\": ask_question(\"Do you have a runny nose?\"),\n",
        "        \"sore_throat\": ask_question(\"Do you have a sore throat?\")\n",
        "    }\n",
        "\n",
        "# Running the expert system\n",
        "if __name__ == \"__main__\":\n",
        "    symptoms = get_input()\n",
        "    engine = Diagnosis()\n",
        "    engine.reset()\n",
        "\n",
        "    for symptom, value in symptoms.items():\n",
        "        engine.declare(Fact(**{symptom: value}))\n",
        "    engine.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtJuFpJeaZsP",
        "outputId": "9e2c8e2d-7c25-4dba-c783-62c997ab30c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you have a cough? (yes/no): yes\n",
            "Do you have a fever? (yes/no): no\n",
            "Do you feel fatigue? (yes/no): no\n",
            "Do you have breathing difficulty? (yes/no): yes\n",
            "Are you sneezing? (yes/no): no\n",
            "Do you have a runny nose? (yes/no): no\n",
            "Do you have a sore throat? (yes/no): yes\n",
            "Diagnosis: You may have Asthma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class SistemPakarMedis(KnowledgeEngine):\n",
        "  @Rule(Fact(demam=True) & Fact(batuk=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis: Flu\")\n",
        "\n",
        "  @Rule(Fact(sakit_tenggorokan=True) & Fact(demam=False))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis: Radang Tenggorokan\")\n",
        "\n",
        "  @Rule(Fact(nyeri_otot=True) & Fact(nyeri_perut=True))\n",
        "  def hernia(self):\n",
        "    print(\"Diagnosis: Hernia. Innalillahi\")\n",
        "\n",
        "  @Rule(Fact(kanker=True) & Fact(tbc=True) & Fact(tipus=True) & Fact(tumor=True))\n",
        "  def mati(self):\n",
        "    print(\"Maot didinya mah\")\n",
        "\n",
        "#Running the expert system\n",
        "engine = SistemPakarMedis()\n",
        "engine.reset()\n",
        "engine.declare(Fact(kanker=True))\n",
        "engine.declare(Fact(tbc=True))  #input symptoms\n",
        "engine.declare(Fact(tipus=True))\n",
        "engine.declare(Fact(tumort=True))\n",
        "engine.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI9iYZm1mNRa",
        "outputId": "e28b5c4a-b9c9-4964-baa3-8e94b20b4035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnosis: Hernia. Innalillahi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "    inferred = set(facts)\n",
        "    changed = True\n",
        "\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for rule in rules:\n",
        "            if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "                inferred.add(rule[\"then\"])\n",
        "                changed = True\n",
        "    return inferred\n",
        "\n",
        "\n",
        "facts = {\"has_feathers\", \"has_beak\", \"lays_eggs\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_feathers\", \"has_beak\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"lays_eggs\", \"is_bird\"}, \"then\": \"is_chicken\"},\n",
        "    {\"if\": {\"cannot_fly\", \"is_bird\"}, \"then\": \"is_penguin\"},\n",
        "    {\"if\": {\"carnivore\", \"is_bird\"}, \"then\": \"is_eagle\"}\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferred facts:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFmownFUqPcT",
        "outputId": "c809f1b7-d0c2-4a25-e777-161781fb190a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred facts: {'lays_eggs', 'has_feathers', 'is_bird', 'has_beak', 'is_chicken'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chainin(goal, facts, rules):\n",
        "    if goal in facts:\n",
        "        return True\n",
        "    for rule in rules:\n",
        "        if rule[\"then\"] == goal:\n",
        "            if all(backward_chainin(cond, facts, rules) for cond in rule[\"if\"]):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "facts = {\"likes_computers\", \"solves_problem\", \"like_to_design\"}\n",
        "rules = [\n",
        "    {\"if\": {\"likes_computers\", \"solves_problem\"}, \"then\": \"should_be_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"likes_programming\"}, \"then\": \"software_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"like_to_design\"}, \"then\": \"UI/UX_engineer\"},\n",
        "]\n",
        "\n",
        "goal = \"UI/UX_engineer\"\n",
        "result = backward_chainin(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? ->\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JCcYUiytt80",
        "outputId": "c535adb1-2e41-44b5-ffbd-8cb5935b8045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'UI/UX_engineer' provable? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "    inferred = set(facts)\n",
        "    changed = True\n",
        "\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for rule in rules:\n",
        "            if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "                inferred.add(rule[\"then\"])\n",
        "                changed = True\n",
        "    return inferred\n",
        "\n",
        "\n",
        "facts = {\"has_wheels\", \"has_engine\", \"has_four_wheels\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_wheels\", \"has_engine\"}, \"then\": \"is_vehicle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_two_wheels\"}, \"then\": \"is_motorcycle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_four_wheels\"}, \"then\": \"is_car\"},\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferred facts:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFixpOj6yMit",
        "outputId": "929f8daa-a82c-4ad4-e045-614f2850387e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred facts: {'is_car', 'has_engine', 'has_four_wheels', 'is_vehicle', 'has_wheels'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chainin(goal, facts, rules):\n",
        "    if goal in facts:\n",
        "        return True\n",
        "    for rule in rules:\n",
        "        if rule[\"then\"] == goal:\n",
        "            if all(backward_chainin(cond, facts, rules) for cond in rule[\"if\"]):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "facts = {\"has_feathers\", \"has_small_wings\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_feathers\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"has_small_wings\"}, \"then\": \"cannot_fly\"},\n",
        "    {\"if\": {\"is_bird\", \"cannot_fly\"}, \"then\": \"is_penguin\"},\n",
        "\n",
        "]\n",
        "\n",
        "goal = \"is_penguin\"\n",
        "result = backward_chainin(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? ->\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxUyKhEE0-XN",
        "outputId": "1bdcc326-aa91-4f04-ce55-c504287c48b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'is_penguin' provable? -> True\n"
          ]
        }
      ]
    }
  ]
}